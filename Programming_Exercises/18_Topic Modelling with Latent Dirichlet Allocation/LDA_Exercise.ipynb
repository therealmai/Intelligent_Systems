{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "# do this before running\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents  = [\n",
    "    \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "    \"Latent Dirichlet Allocation is a generative probabilistic model.\",\n",
    "    \"Topic modeling is used to identify topics present in a corpus of text.\",\n",
    "    \"Gensim is a popular Python library for topic modeling and document similarity.\",\n",
    "    \"Dota 2 is a popular MOBA PC game available on Steam. It is known for being difficult and non-beginner friendly gamplay mechanics.\",\n",
    "    \"Do something now that your future you will be thankful for.\",\n",
    "    \"Nothing will ever change. Everything will stay the same. You will always be on the same spot unless you take the first step.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Tokenize and lemmatize using spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_documents = [preprocess(doc) for doc in documents2]\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model_3 = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "\n",
    "lda_model_6 = gensim.models.LdaModel(corpus, num_topics=6, id2word=dictionary, passes=15)\n",
    "\n",
    "lda_model_9 = gensim.models.LdaModel(corpus, num_topics=9, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print topics and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 3 topics\n",
      "[(0,\n",
      "  '0.081*\"topic\" + 0.056*\"modeling\" + 0.032*\"similarity\" + 0.032*\"document\" + '\n",
      "  '0.032*\"Gensim\" + 0.032*\"library\" + 0.032*\"Python\" + 0.032*\"present\" + '\n",
      "  '0.032*\"text\" + 0.032*\"identify\"'),\n",
      " (1,\n",
      "  '0.023*\"future\" + 0.023*\"thankful\" + 0.023*\"change\" + 0.023*\"spot\" + '\n",
      "  '0.023*\"stay\" + 0.023*\"step\" + 0.023*\"popular\" + 0.023*\"Dirichlet\" + '\n",
      "  '0.023*\"probabilistic\" + 0.023*\"generative\"'),\n",
      " (2,\n",
      "  '0.039*\"popular\" + 0.039*\"MOBA\" + 0.039*\"mechanic\" + 0.039*\"available\" + '\n",
      "  '0.039*\"friendly\" + 0.039*\"pc\" + 0.039*\"Dota\" + 0.039*\"Steam\" + '\n",
      "  '0.039*\"gamplay\" + 0.039*\"game\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 3 topics')\n",
    "pprint(lda_model_3.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 6 topics\n",
      "[(0,\n",
      "  '0.127*\"thankful\" + 0.127*\"future\" + 0.018*\"spot\" + 0.018*\"stay\" + '\n",
      "  '0.018*\"change\" + 0.018*\"step\" + 0.018*\"topic\" + 0.018*\"modeling\" + '\n",
      "  '0.018*\"popular\" + 0.018*\"artificial\"'),\n",
      " (1,\n",
      "  '0.153*\"topic\" + 0.082*\"modeling\" + 0.082*\"text\" + 0.082*\"corpus\" + '\n",
      "  '0.082*\"identify\" + 0.082*\"present\" + 0.012*\"future\" + 0.012*\"spot\" + '\n",
      "  '0.012*\"thankful\" + 0.012*\"stay\"'),\n",
      " (2,\n",
      "  '0.055*\"popular\" + 0.055*\"non\" + 0.055*\"mechanic\" + 0.055*\"beginner\" + '\n",
      "  '0.055*\"Dota\" + 0.055*\"pc\" + 0.055*\"Steam\" + 0.055*\"difficult\" + '\n",
      "  '0.055*\"game\" + 0.055*\"gamplay\"'),\n",
      " (3,\n",
      "  '0.089*\"probabilistic\" + 0.089*\"Latent\" + 0.089*\"Dirichlet\" + '\n",
      "  '0.089*\"Allocation\" + 0.089*\"generative\" + 0.089*\"model\" + 0.013*\"thankful\" '\n",
      "  '+ 0.013*\"future\" + 0.013*\"topic\" + 0.013*\"stay\"'),\n",
      " (4,\n",
      "  '0.089*\"natural\" + 0.089*\"intelligence\" + 0.089*\"subfield\" + '\n",
      "  '0.089*\"language\" + 0.089*\"processing\" + 0.089*\"artificial\" + 0.013*\"future\" '\n",
      "  '+ 0.013*\"thankful\" + 0.013*\"topic\" + 0.013*\"spot\"'),\n",
      " (5,\n",
      "  '0.061*\"library\" + 0.061*\"Gensim\" + 0.061*\"document\" + 0.061*\"Python\" + '\n",
      "  '0.061*\"similarity\" + 0.061*\"step\" + 0.061*\"change\" + 0.061*\"stay\" + '\n",
      "  '0.061*\"spot\" + 0.061*\"popular\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 6 topics')\n",
    "pprint(lda_model_6.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model 9 topics\n",
      "[(0,\n",
      "  '0.119*\"topic\" + 0.063*\"Dirichlet\" + 0.063*\"probabilistic\" + 0.063*\"model\" + '\n",
      "  '0.063*\"Latent\" + 0.063*\"generative\" + 0.063*\"Allocation\" + 0.062*\"corpus\" + '\n",
      "  '0.062*\"present\" + 0.062*\"identify\"'),\n",
      " (1,\n",
      "  '0.023*\"future\" + 0.023*\"thankful\" + 0.023*\"modeling\" + 0.023*\"topic\" + '\n",
      "  '0.023*\"step\" + 0.023*\"stay\" + 0.023*\"popular\" + 0.023*\"present\" + '\n",
      "  '0.023*\"spot\" + 0.023*\"change\"'),\n",
      " (2,\n",
      "  '0.103*\"language\" + 0.103*\"artificial\" + 0.103*\"subfield\" + '\n",
      "  '0.103*\"intelligence\" + 0.103*\"processing\" + 0.103*\"natural\" + '\n",
      "  '0.010*\"future\" + 0.010*\"thankful\" + 0.010*\"topic\" + 0.010*\"change\"'),\n",
      " (3,\n",
      "  '0.059*\"gamplay\" + 0.059*\"Steam\" + 0.059*\"beginner\" + 0.059*\"pc\" + '\n",
      "  '0.059*\"non\" + 0.059*\"difficult\" + 0.059*\"game\" + 0.059*\"MOBA\" + '\n",
      "  '0.059*\"available\" + 0.059*\"friendly\"'),\n",
      " (4,\n",
      "  '0.023*\"future\" + 0.023*\"thankful\" + 0.023*\"stay\" + 0.023*\"topic\" + '\n",
      "  '0.023*\"modeling\" + 0.023*\"step\" + 0.023*\"change\" + 0.023*\"probabilistic\" + '\n",
      "  '0.023*\"popular\" + 0.023*\"artificial\"'),\n",
      " (5,\n",
      "  '0.164*\"thankful\" + 0.164*\"future\" + 0.016*\"topic\" + 0.016*\"modeling\" + '\n",
      "  '0.016*\"popular\" + 0.016*\"Allocation\" + 0.016*\"artificial\" + 0.016*\"stay\" + '\n",
      "  '0.016*\"change\" + 0.016*\"spot\"'),\n",
      " (6,\n",
      "  '0.127*\"stay\" + 0.127*\"spot\" + 0.127*\"step\" + 0.127*\"change\" + '\n",
      "  '0.013*\"future\" + 0.013*\"thankful\" + 0.013*\"topic\" + 0.013*\"modeling\" + '\n",
      "  '0.013*\"intelligence\" + 0.013*\"probabilistic\"'),\n",
      " (7,\n",
      "  '0.023*\"topic\" + 0.023*\"text\" + 0.023*\"modeling\" + 0.023*\"identify\" + '\n",
      "  '0.023*\"present\" + 0.023*\"corpus\" + 0.023*\"future\" + 0.023*\"thankful\" + '\n",
      "  '0.023*\"change\" + 0.023*\"probabilistic\"'),\n",
      " (8,\n",
      "  '0.087*\"modeling\" + 0.087*\"popular\" + 0.087*\"Gensim\" + 0.087*\"Python\" + '\n",
      "  '0.087*\"document\" + 0.087*\"similarity\" + 0.087*\"library\" + 0.087*\"topic\" + '\n",
      "  '0.009*\"future\" + 0.009*\"thankful\"')]\n"
     ]
    }
   ],
   "source": [
    "print('LDA Model 9 topics')\n",
    "pprint(lda_model_9.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topics to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.047890186), (1, 0.04845486), (2, 0.903655)]\n",
      "Document 2 - Topic: [(0, 0.9033362), (1, 0.04864654), (2, 0.04801727)]\n",
      "Document 3 - Topic: [(0, 0.91578436), (1, 0.042299073), (2, 0.04191659)]\n",
      "Document 4 - Topic: [(0, 0.9242065), (1, 0.03769536), (2, 0.038098145)]\n",
      "Document 5 - Topic: [(0, 0.022521215), (1, 0.022605065), (2, 0.9548737)]\n",
      "Document 6 - Topic: [(0, 0.7741827), (1, 0.11371442), (2, 0.11210286)]\n",
      "Document 7 - Topic: [(0, 0.8646352), (1, 0.068131074), (2, 0.06723372)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_3.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.023810547), (1, 0.023810193), (2, 0.023809984), (3, 0.023810241), (4, 0.880949), (5, 0.023810025)]\n",
      "Document 2 - Topic: [(0, 0.023810547), (1, 0.023810193), (2, 0.023809984), (3, 0.880949), (4, 0.023810241), (5, 0.023810025)]\n",
      "Document 3 - Topic: [(0, 0.020834135), (1, 0.895785), (2, 0.020833693), (3, 0.020833895), (4, 0.020833895), (5, 0.02087945)]\n",
      "Document 4 - Topic: [(0, 0.018519677), (1, 0.018652756), (2, 0.01854244), (3, 0.018519329), (4, 0.018519329), (5, 0.90724653)]\n",
      "Document 5 - Topic: [(0, 0.011111867), (1, 0.011111605), (2, 0.944432), (3, 0.01111164), (4, 0.01111164), (5, 0.011121212)]\n",
      "Document 6 - Topic: [(0, 0.7222168), (1, 0.05555674), (2, 0.055556368), (3, 0.05555683), (4, 0.05555683), (5, 0.055556446)]\n",
      "Document 7 - Topic: [(0, 0.033335503), (1, 0.033334747), (2, 0.033334304), (3, 0.033334848), (4, 0.033334848), (5, 0.83332574)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_6.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.015873047), (1, 0.01587305), (2, 0.87301564), (3, 0.015873047), (4, 0.01587305), (5, 0.015873048), (6, 0.015873048), (7, 0.01587305), (8, 0.015873047)]\n",
      "Document 2 - Topic: [(0, 0.87301546), (1, 0.015873069), (2, 0.015873065), (3, 0.015873063), (4, 0.015873069), (5, 0.015873067), (6, 0.015873065), (7, 0.015873069), (8, 0.015873065)]\n",
      "Document 3 - Topic: [(0, 0.88888454), (1, 0.013888928), (2, 0.013888925), (3, 0.013888924), (4, 0.013888928), (5, 0.013888926), (6, 0.013888925), (7, 0.013888928), (8, 0.0138929635)]\n",
      "Document 4 - Topic: [(0, 0.012348668), (1, 0.01234571), (2, 0.012345708), (3, 0.012346512), (4, 0.01234571), (5, 0.012345709), (6, 0.012345708), (7, 0.01234571), (8, 0.9012306)]\n",
      "Document 5 - Topic: [(3, 0.9407399)]\n",
      "Document 6 - Topic: [(0, 0.037037082), (1, 0.037037086), (2, 0.037037082), (3, 0.037037082), (4, 0.037037086), (5, 0.7037033), (6, 0.037037082), (7, 0.037037086), (8, 0.037037082)]\n",
      "Document 7 - Topic: [(0, 0.022222258), (1, 0.02222226), (2, 0.022222258), (3, 0.022222258), (4, 0.02222226), (5, 0.02222226), (6, 0.82222193), (7, 0.02222226), (8, 0.022222258)]\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_9.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding more topics, the weight of each topic becomes smaller. There are some where the weight of a topic has a significanly larger share than the rest regardless of the number of topics. It is essential to assess the quality of topics for a better interpretability of the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
